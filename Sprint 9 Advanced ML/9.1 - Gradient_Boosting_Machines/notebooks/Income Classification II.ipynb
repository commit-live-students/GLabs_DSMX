{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Gradient Boosting and XGBoost</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Program so far\n",
    "***\n",
    "- Linear and Logistic Regression\n",
    "- Decision Trees\n",
    "- Ensembling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John does it again\n",
    "***\n",
    "John was desperately looking for a pair of clothes when Lucius arrived to pick him up. Looking at the pile dirty laundry, Lucius couldn't stop himself but comment: \"John, why do you keep on making the same mistakes? It takes exactly 20 minutes to get your laundry done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's thoughts\n",
    "***\n",
    "John started thinking aloud, wouldn't it be great if we could literally learn from our mistakes, and try to avoid/minimize it in the future?\n",
    "\n",
    "This thought rattled his mind, when he had forgotten the laundry for umpteenth time as he was busy building models.\n",
    "He wondered, whether this idea could be applied, to his just build model?\n",
    "That would surely be interesting, and his model would surely outperform him.\n",
    "\n",
    "To Lucius's frustration, John went berserk, and searched over the entire internet for such a thing, and when he found it, he was so happy.\n",
    "**BOOSTING**, he muttered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Boosting (1/3)\n",
    "***\n",
    "The idea of boosting came out of the idea of **whether a weak learner can be sequentially modified to become better.**\n",
    "\n",
    "\n",
    "Boosting (aka hypothesis boosting) refers to any Ensemble method that can combine several weak learners into a strong learner.\n",
    "\n",
    "The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Boosting (2/3)\n",
    "***\n",
    "Hypothesis boosting works by filtering observations, leaving those observations that the previous weak learners can handle and focusing on developing new weak learns to handle the remaining difficult observations.\n",
    "\n",
    "\n",
    "Boosting improves by reducing bias of every subsequent weak learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Boosting (3/3)\n",
    "***\n",
    "_The idea is to use the weak learning method several times to get a succession of hypotheses, each one refocused on the examples that the previous ones found difficult and misclassified._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Boosting Intuition\n",
    "***\n",
    "This far into the intro and the mathematician in Lucius started taking over. We will go partying some other time, thought Lucius, as this is a matter of utmost importance. No wonder both John and Lucius were both single!\n",
    "\n",
    "Lucius started reading and explaining: Let's say we have been given a binary classification problem as shown in the boxes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "\n",
    "**Step 1.1:**\n",
    "We start with box 1, we employ a weak learner which creates a boundary D1, which predicts blue region as positive and red region as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "\n",
    "**Step 1.2:**\n",
    "Hence, we have identified 2 observations on the left hand side correctly positive, but we marked three positive observations on the right side incorrectly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "\n",
    "**Step 2.1:**\n",
    "We come to box 2.\n",
    "We employ another weak learner. But this time we pay more attention to classify the three positive observations (enlarged +) that we predicted incorrectly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "\n",
    "**Step 2.2:**\n",
    "The learner comes up with the boundary D2, which correctly identifies previously wrongly predicted observations.\n",
    "However, this time it wrongly predicts 3 negative observations as positives (- in blues region)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "**Step 3.1:**\n",
    "We move on to box 3.\n",
    "This time, the objective is to identify the 3 negative observations (enlarged --) correctly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "**Step 3.2:**\n",
    "The weak learner comes up with boundary D3, which identifies the three \"-\" correctly as negatives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## How Boosting Works\n",
    "***\n",
    "\n",
    "![](../images/image21.png)\n",
    "\n",
    "**Step 4:**\n",
    "We combine all the boundaries to come with the boosting model which is a strong learner, made up of weak rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of Boosting\n",
    "***\n",
    "\"But how to perform boosting?\" wondered Lucius, and turned to the best teacher in the world: The internet.\n",
    "\n",
    "There are many types of Boosting, said the internet, however the most popular ones are :\n",
    "\n",
    "* AdaBoost (**Ada**ptive **Boost**ing)\n",
    "* Gradient Boosting\n",
    "\n",
    "Let me tell you more about these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## AdaBoost\n",
    "***\n",
    "AdaBoost is one of the first boosting algorithms to be adapted in solving practices. Adaboost helps you **combine multiple “weak classifiers” into a single “strong classifier”**. Here are some (fun) facts about Adaboost!\n",
    "\n",
    "* The weak learners in AdaBoost are decision trees with a single split, called decision stumps.\n",
    "* AdaBoost works by putting more weight on difficult to classify instances and less on those already handled well.\n",
    "* AdaBoost algorithms can be used for both classification and regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "Lucius ran and brought some papers and a pen to quickly go through the math behind Adaboost, so that he can explain it to John. It went something like this. "
   ]
  },
  {
   "attachments": {
    "image20.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL8AAAA5CAYAAABnA/rDAAAHmklEQVR42u2doXarTBSFeSLegSfgBdCjsVgcEodDoVAoFAaFwWAwCAwGgcAgEPs/M9CEpGkDadPb/D17rVm3tzeTJjPfnNln5uRWA4v1R6XxELAYfhaL4WexGH4Wi+FnsRh+FovhZ7EYfta3qEcSBgijCHEcI6I/ZQuDEEU38fAw/P9fDbkPOywwYUbp69CcDBL5JnHgZj0PEMP//1UVJ+jUVxMiU4NfjsuiqBLkLUd+hv8vaK5haiZK5p3h/2ua6hCaHmDkoWD4/5qa0IQR1DwQDP9fsjst4sCHMHRYjoe4aHlMGH4Wi+FnsRh+Fovhf0VrP7QoigJlWVIrkOf5x40eV6zt7fFFUfNJEMP/mpqqAJqmrU2H53twXfdmcxwbwjKhnx6/tKBi/Bn+14z9yFxjBVmg3MvxNKDKQpiynxXTs7AY/oPqmhZ3L0/nAU07PPFVtHD1NZIbPg5V7syyr464/WX47xyzoeswMfxfHewOWZwgk944SxEnOQaKh1WaIFWemb4XZ+g2jNShgOHlO558QGiRJSmeV1A2t8nJzph+caxznyOIv/cirCsThEGAKGse6N3DN3QE5X34u9SBbqe/Zud60cg/os6jBSARoKgaFVH6OoWhIqqLrKwwzG+wxdB0/0Cy2MB6co1NmzhnH18O/3Q0py5X42bFx+GvAhNmuL9fZutwfkml6uvaniFT8If1dGEpbPqenXbbqVWVkl55LFFsYwHdK56JHBICYVkAFsp/msc2EPQ6DtupsaBFY6GZj82bpjnoGP4vbNWZo6Cp562diBVMydbvqAly3nvrqUdd1einxeo0TYdxO4nT0u+pkzTXarGqBWBFXz/GnEe0dY22P7ZlzU2kgKz7nsahvRyHT22MTVayeJfUt3WFplveTd826C+ecEYijKugxfAfUubKqGkjJ4CrqkJFk576lprEbWXMWHo3TkgocTQshHEAkxJI07IhZBJqRJuEbICvG7i5Q9PCaeqGQPm47QVwqqOT/RHR416+L0PaCXX4SULvjSxMWCrQCsqH7i2qhnY5+fN1O0Ac2PS1u2vRSwtzvaMWngU7iOBZBgyTvhbLe9tayMo3yCrVDP+DcR+umiwfSRKrj/4lSbDkAM5lQjUWHkWn8sqnCgTVpHIHj/o4eY8+82CH5UVeEdCCcIv3fnxqUzi2Dcdxbjf6Nz/Z74OrUJwWQFgd9/9zs+54b7alT9VRak1e3nazk693hYO0md7Zr9iin02J6PJkJe14OvIRd/qN8DVpJ4eLHcR0l0OFOjAo6CQYKUEXlJdtF1MdWdDdguF/LMylCyhbz/Pm95PLikgZZfQr+Efa3lXPMacFY6AYbyfVPsEf1D9hxkdE1gK/lx01WktOIz/6eP5WCZMAtoVAfDLkPQUM4wT11npZG7+vdkrNw7A5zbnZbw0O9mZrnIdutZETQuM699q8vMqHwfA/yP7q96vpk+i3sT3GB4nrUMiJ9peJHjvyqdO+yN8ksC0BmyL8zUbQecmBbX1u4MjTlrB6aOHI1ym2i36uFNCnaL4mmoYRLJ8NLku061HYpPy+fbKKuUP9aLyGroEajg/63Yr82wVlnnKvCW176R0bjvxf8Ptygszowt7IrVR61WuL/t7zd/AMeVE0ICU/qvsLcLlrIWqmq8hPnv+WC5kGmtD209btTjoHBMYC6mPn3wuE7sZ7L4cBBqpZXiwtb2DIXbIkZA/DEKFnQlvhkyBKezIvIVkdeWZ9h8By0XzSb5kHA94mOJSBpe4tusJVudeg1mEAyy/f7cZmxJ7/2AZPXluYhvL2umFAuCkmipqeWGtgCFZT+LhkWJ7anCObjLLyWE+jZEzYAqZBUZrAt64vm8b8+ac9stxBLmSKrF856R8qeedhwg8DOMKCEyYIbfLclMw769l94ZtqZ7TXXGTeWCYrbi8Cg0Xj+Wa/bvc7n/bo7vniMHeXmiUhbJonE45PC8d00V6959ji056fWjJqgi/ty4RhGE/Hg33/Hj31kcKriPXdqkNLWY5m/p73OVAuM83bv49n365Lm9iRvaIch7x5tt7mztN0teNMNB73+50Dy+Vx8zQM64nZrF7PeDNf43P+H9PhG16VBF7mFN+et+SeipL5wcvOsfBP0Xx/p/zk2zNX0I7nIttzobWj33LDu9/CpEKHm/MN74+qiQQMN9vhq8mDmzr8J5YcTGtyHh4sTx7bdDmGfOClzfPZdozj/I39lvEKqp21PU76a5j4U1Wdfdvdh19VKD7xeHMoVFLp7DnSJPLGoUdT5Qhda7kLEMkvLGke0Xb3x4yrOv+yplodaSqIdf3iQyp7m1cMPI4M/wuy3+bw/QChPDYMAgSftnB53KnJ78UXZdoshp/FYvhZLIafxWL4f6Hv/7BKckffvkHNv6yC4X9dfVQl+Sn2yCNfFYu5fNrD8L+sPqySvK/KNxl+hv+F2b9RJSlLpMWtEmlVGn0uZSg9hp/hf2F9ViV5Tww/w//afv9GlaT6cIyw70Z+aXs8/p1FDP9L6tHqSvUfckWwTR265SCMC/ASYPhfTo9WV7IYfhaL4WexGH4Wi+FnsRh+FovhZ7EYfhaL4WexzvoPit8LzZe2oU8AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "Suppose we are given a training set D = {(x1, y1),(x2, y2)...(xn, yn)}, where xi ∈ RD and y ∈ {+1, −1}. \n",
    "Our weak classifiers are functions h : x → y. The strong classifier has the following form:\n",
    "![image20.png](attachment:image20.png)\n",
    "\n",
    "We want to figure out how to choose the T weak classifiers h<sub>k</sub>."
   ]
  },
  {
   "attachments": {
    "image27.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "We want minimize the exponential loss.\n",
    "The exponential loss function is\n",
    "![image27.png](attachment:image27.png)\n",
    "\n",
    "\n",
    "We are using exponential loss function instead of 1/0 loss function, because it is differentiable.\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image26.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "Suppose we have the first t weak classifiers, and now we are interested in choosing h<sub>t+1</sub> and the corresponding weight α<sub>t+1</sub>.\n",
    "We can pose the t + 1 iteration of AdaBoost as the following optimization:\n",
    " \n",
    "![image26.png](attachment:image26.png)"
   ]
  },
  {
   "attachments": {
    "image28.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "Note that the factor e<sup>−yiHt(xi)</sup> does not depend on the arguments of the min operation \n",
    "So we can regard it as a constant, which we can think of as a weight for each point at iteration t which we will denote w<sub>t</sub>(i).\n",
    "\n",
    "Let’s continue to manipulate the algebra:\n",
    "\n",
    "![image28.png](attachment:image28.png)\n"
   ]
  },
  {
   "attachments": {
    "image22.png": {
     "image/png": "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"
    },
    "image25.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost \n",
    "***\n",
    "We can see that h<sub>t+1</sub> =  arg min<sub>t</sub>![image25.png](attachment:image25.png) \n",
    "Let 𝜖t = ![image25.png](attachment:image25.png)\n",
    "We must solve the following equation :\n",
    "![image22.png](attachment:image22.png)"
   ]
  },
  {
   "attachments": {
    "image23.png": {
     "image/png": "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"
    },
    "image35.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAByCAYAAACP8Uc4AAAMdElEQVR42u2dO4+kRheG+UX8AicEjvkDxMhhpaSVkVhCTsiIiIiIWpZMQkSCZJGQIJkEBwR8ErJFgKX3q6ru6emZ7dmdS09PX95HQt7e0Q4eph7OOXW1QAi5SSw+AkIoNyGEchNCKDchhHITQig3IZT7Uv5H+rpEnhdox4W/FUJuRe428SGyBmNXwLMspB0FJ+Qm5M49G1E9b0WPHViy2n9tbGuUVQ0GdEKuuuYeEewj94RMuBBphb5J4bgpxr5AVk83/0tZpgnX8S5bMXQdun5UfyKU+0UmpL4LuenNp7mJYHn5Q3NH4tpwvBDdCVvRui4XJUpfF4ilB8uyUc2X3nQmJCrj8sIEiXTV7yrFRJ8o93GxPSSNatFzjTjvVHruwk26JxE9rE7bfCrVKB/KgUuQuy1L1HUG23IuXu420UJn+8+ZZ8GJGxp173Iv04C27TDvonAZqjpbyWurS/831pJPFXw3QLbJEYchpPDg+QE2RzrblnnGPL89CtehyhTe8MJ4733e9nBqOBcv94zItiA2w/5vGt1Xokondo3crdyqjg7UG9+VyDcxHCdSMfkDFXqdwlUvA9f3EUTFmxvWa+X+6H2+RO5lRKdeoF338tW/u5dyK3d4kPU0KtOy7Iip+X3KvaKUKjI7ybbzZe0gnAD9e9tum5gon/fvL8Ir6fxQ7lPc5yvkXvoNAiEQBMHxS30tyrsPyv347KYqNHLPdOoO5VaNVkc/y/EhAwHPE8jb977nF2T+NoX3hK++l0TzEITmEq4TH21kReipBuiojGF7WaYMsPefbfVnU/e/5j4qRoWOh/pY8FtbBI4N23m81+H17X2uMy0/jNx1pJ6nHVPue5X7dI12Mo3L30Wedd1G1XnsUWVCpf0xuunHKadJy8vpzfdZ5xFtlSpJPZTdeJHPaelyCM+HUBH66KVKjDBv3y137KgyJWmepuUO5b5bue0nQzwDYl/gfZ3VKzbCgh09Nq5lWTEPDaSWMSnQ9tPr5P5uWn78PlgG5Cqlt0SCuu1PO8Y7FSpTcI5nBG963hP6vv/uNXxgZtC2tzzff2Zv+V3X3OrtnvoqqgZIklClzh6y5gPdL1MNYdsQYQTpPYyPq1TZdlG9ss2+qkPt6H22w2jhSYfRFhSRUM/F3pYKrrpX1l5w0xkQqejthSlSXe6obGmkT/cr9zalnTCOp5rRtGJS32s6rLfdRGnSI9/8uLOoCl87zv3sPrt6u1V3KrPijlNR9aTbBnXTcQiMcn9+6i+8AGEQovrUMZkZiapZZaiykJqDP4Rynys12E+O+eQbYZ45o5pQbkII5SaEUG5CCOUmn8wyYVrYB0G5yc0wdTXyJDRTdMOKIweUm9wMY1OirEsI6+lCEkK5yW3k5Ijtz5N7XWZM08ytnCg3OT/fLgE9zbdtEXo2LMeDEBG4KS7lJrcgt17vr5fapi0fL+W+IhX6Gpt8g6od70Pud6xvn+rIdNK5voCvF+wcbCxxWXvfUW7yUJ22CRyRYZw6RK4FP+tuX+538GTbpt06ej21uO8qE9GjkotVKPeF0Wc+nKjeBTQdncL9vmPL2KIqK3RXdwLDQ4fa6aKp2drako97si2LeYk0uVR/L1DULSb2sFHuS6UQuqbcRu4mFSqip+gHvX7cRzN2SNP68l9WRQTPdWHbOu12zVZU7UneTTPyQKXsvkQkfbhBbiL1XIVwwpqNh3JfLk0i4MrNdnjHbK0k9ptFtrFneohzdg9/g663Y/VchjJHy7Kbcl+i2MLsPzYhizf4XxsrmdP9OG6pt3YKKz6ol56dlJAJozfl/mp0J1Dbot9t4zKW26malr3dVdWNdSMdEfs+4nyDNAoRSr07rPq86fj8jiXsMzMayn0B9aje7DDOc0jXQdafsQfoUw8lIJT7nqNLE5uNDstdXbgRzlnHZj/3UIItv/32G37++ecvvf744w82Nsp9Th4PMxAygO95kGl9c3OjW1Vu/P777196/f3332xulPuscdtM6giK4eteL596KAGh3HccuVNXy/04vVSPY4tzzkb75EMJCOW+X71V5NTHAkVJgsBzIOKKSxYJ5b4Z1sUcwDAxQBLKTQih3OS6y5Z55mQUyk1uibFOzTntru8jiAou26Tc5CaidZuYsf+8Z9ci5Sa3pPZ+Yo8nfLM0tHl2amrNME65yTUymYk9/m7K67rbXWWdR7RVCtvyUHY84ZtykytkxUYvZY2ax1iuTyhZBuTSgSUS1G3PuQCUm1xn8Na7zNgQYQSpNz3cbLen0BswhNzwkHKT64/g05OJPdt6u1U1eZkVoOKUm9wMMxLfhwwDJDyOiHITQig3IZSbEEK5CSGUm9wNy4Rp+apR6hUT19VSbnJapq5Gnmy3aw6r8/Z2r1OHcpPCt7jPO+UmJ2dsSpR1aQ7nC888lLWODYqyQuLrmW88pIByk8/IyXcHAX7NOHUTOSpyf57c17r2nHKTE3D6I3zfQv1Jcl/72nPKTSj3sWh9A2vPKTe5ebnbVMCyHTjOkUsvQ02ab8qMF9eezyVcJ76KOfCUmzByf8Pxtefz2KPK1IvCjdFdwdAb5SanSGJ3HWpfE890h5oVFCf8jsfXns9DA2kifYG2nyg3uW30Saae68K2bdiOa1LY9nlQWwds0gRxkmM4ZQm7dAh9V6XWtjl00XV9bLoTRdSja88nhLaL6kp61ig3OUva3mwiI2B1VQu2n6091/W2m6g8pUd+BWenU25yJk8ac7xSdc27MSwqmnsBwiBEdQVLzyn3KTK4vkPbDdz/6wdiPJd7nXrUVYXmm/p1xdi36IYJ6zqhLkt004U83XXGfCW/aMr9oWyzhXQsuDJFFnmwnAiDKddKtF8doZYRXduh616++nOe8vlM7n4jVZruI1dyJ0LV6yLbDS+NiF0LjkyQBI4ZjgqkByfk9FLKfTYGSD17aT9GOiNUn6OmRyYk2ne/3Rd0Tfvh2VBLv0EgBIIgOH6pr0X5x+rGX3/9FT/99NPR659//nlZ7rEw0pb7gD2ZZ+dlHZYmVl8T5iWJVf8bG5sjvXB//fXXi/c+1/XLL79Q7ltkLHTk8Q4knhGrKC4iCRE/Rpm5CuEeWdTQJOFB434QskQodLQKcQ27ienoX6qU+dj133//vSj3XEcmancHztahbVZ2rX2mvuai0V9bKvMSKI48jH///ffFe5/r+vPPPyn3LaInTlhO8mSmUpu4T4TXdWOmUk43Lr85xreKgm/kxi5aufbH5dbngwvPh1AR+ujl+wjz9kvS8q3c7sGJI0AZWLD0sk3T8aYyIhFAuA5k1rAvg3KfOWqlSmQvO+hVaxBY2wa6LrNJq4cmN2llUtTon3UI1SrCl8fq8rlSckcfj9zLhL7vv3sN56y5d73l5sigqYStnlX2MCa9tvB0bV0M5uf3vRjt0KvMoMfEk0Ap99lZO0jHhh/GiKSAJyLkqYRtO3D9dBvRzTzkaF8/d3kIz1dRMxAmOjn+Nor6nkDezQdyX0da/vhCGo2I40vdyEsL6W47xywnMJNcpiY1L74giuCbWV/VNkKrn18/G+vwsoMnKTyh3Odp19Ooosv65PNyWG/HHdahxOZZ9/n30/LoapYX6hlqjisQq59Hi+jH1RvS6O0kkcPgnLnqe2yGwyeMzLMgK+5pTrkvSfwmURFdQsoUz4+4Oya33lkkCYVKWR0EKiOohktXvDNRNhsff14teNy8fxywCvW5YRmG3X5sU1+alD3jsb+U++Ky93k+GsnqWKK49kMtVQqta2cnbva1s/vh7ZYWtEX6OGQnY5TdaaO27hOZpvnmO+ooN/mIJhi7Dg/9cmuXmcidtBeaccwtQs9Wdb8HISJ0C+Um5DXmmHF+y88ucyODtTObOHppeze/EcpNTkIpVUT0kovdoWQyY+t6PzQ9OuFCHszO00cIRzd4hDDlJh+mTX04wWZbw06NqpEvT5QmdmE9zB/Y7ayiF4H0XWUielR2WCg3IY8MhTCzzYqmQV3XyKR39sMJXlU0NDpyy8f5A8tiSokml2Yue1G3mFbKTchOkMb0jj+ZcKJEv8wMd0YeOLB9iUj6cIPcRGo9F+FWV5xRbnJf76N5wjjNT+rtuFswlPnXL9Ol3IScsBZPBISUkMntRW/KTe6e+UYXp1BuQm4Uyk0I5SaEUG5CCOUmhFBuQgjlJoRQbkIoNyGEchNCKDchhHITQig3IYRyE0K5CSGUmxBCuQkhlJsQQrkJIZSbEMpNCKHchBDKTQj5HP4PhtOfXOrbn6MAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost\n",
    "***\n",
    "\n",
    "![image35.png](attachment:image35.png)\n",
    "\n",
    "With a bit more manipulation we can prove that :\n",
    "![image23.png](attachment:image23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Math behind AdaBoost\n",
    "\n",
    "***\n",
    "* As you can see, this sequential learning technique has some similarities with Gradient Descent, \n",
    "* However,  instead of tweaking a single predictor’s parameters to minimize a cost function, AdaBoost adds predictors to the ensemble, gradually making it better.\n",
    "* Once all predictors are trained, the ensemble makes predictions very much like bagging or pasting, except that predictors have different weights depending on their overall accuracy on the weighted training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Maths-Insight.png\" alt=\"Maths-Insight\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## AdaBoost Algorithm\n",
    "***\n",
    "\n",
    "![](../images/image35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Adaboost in `sklearn`\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), \n",
    "                             n_estimators=200,\n",
    "                             algorithm=\"SAMME.R\", \n",
    "                             learning_rate=0.5, \n",
    "                             random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Need for generalization\n",
    "***\n",
    "John was thrilled to learn the Adaboost algorithm, but something was not quite right. Adaboost can only be possible if use `exponential loss` function as the loss function. What if we wanted to use an arbitrary loss function? Let's say MSE or f1 score?\n",
    "\n",
    "This is where Gradient Boosting Machine comes in, said Lucius, after finishing his long read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generalizing Boosting: Gradient Boosting Introduction (1/2)\n",
    "***\n",
    "**GBM is a generalized version of AdaBoosting.**\n",
    "\n",
    "Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generalizing Boosting: Gradient Boosting Introduction (2/2)\n",
    "***\n",
    "However, instead of tweaking the instance weights at every iteration like AdaBoost does, **this method tries to fit the new predictor to the residual errors made by the previous predictor.**\n",
    "\n",
    "A benefit of the gradient boosting framework is that a new boosting algorithm **does not have to be derived for each loss function that may want to be used, instead, it is generic enough framework so that any differentiable loss function can be used.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "GBM uses Gradient Descent to find the shortcomings in the previous learner's predictions.\n",
    "\n",
    "\n",
    "Let's understand GBM using a toy regression data. \n",
    "If the loss function is MSE, then gradients are the residuals.\n",
    "In such a case, the GBM algorithm can be given by following steps.\n",
    "\n",
    "* Fit a model to the data,  F1(x) = y\n",
    "* Fit a model to the residuals,  h1(x) = y−F1(x)\n",
    "* Create a new model,  F2(x) = F1(x) + h1(x)\n",
    "\n",
    "Let's understand this using an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "We start by making a dataset which roughly follows the relationship $y = 3x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Now let's write a function to plot the models that we are going to train on the original data as well as the residuals. If this seems confusing, don't worry, you will get a better idea once we start fitting the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], 500)\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Now let's fit the first decision tree as usual on the data, find out the residuals for each point and save them in a variable called y2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)\n",
    "y2 = y - tree_reg1.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Plotting the decision boundary looks something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plot_predictions([tree_reg1], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1)$\", data_label=\"Training set\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "plt.title(\"Ensemble predictions\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Now, as mentioned before, GBM fits models sequentially to correct the errors by the previously fit models. So, let's fit the next model on the residuals (y2) and X. Also, we will calculate the errors made by this model, and save it in y3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)\n",
    "y3 = y2 - tree_reg2.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Now, the graph on the left hand side shows how the second model fits the model on the residuals.\n",
    "\n",
    "The graph on the right hand side shows the collective predictions made by 1st and 2nd model on the original data. As can we can notice, the fit is better than just the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_predictions([tree_reg2], X, y2, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_2(x_1)$\", style=\"g-\", data_style=\"k+\", data_label=\"Residuals\")\n",
    "plt.ylabel(\"$y - h_1(x_1)$\", fontsize=16)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([tree_reg1, tree_reg2], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1)$\")\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Now, let's repeat the same process for y3. We will be fitting just 3 sequential models, so we will not calculate the errors by the third model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Predicting a token value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Boosting Algorithm Intuition\n",
    "***\n",
    "Finally, the left hand side graph shows how the third model fits the errors from the second model. Also, notice how the errors are gradually converging to 0 with each iteration.\n",
    "\n",
    "The graph on the right hand side shows the collective predictions made by 1st, 2nd and 3rd model on the original data. As can we can notice, the fit is better than the previous iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_predictions([tree_reg3], X, y3, axes=[-0.5, 0.5, -0.5, 0.5], label=\"$h_3(x_1)$\", style=\"g-\", data_style=\"k+\")\n",
    "plt.ylabel(\"$y - h_1(x_1) - h_2(x_1)$\", fontsize=16)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([tree_reg1, tree_reg2, tree_reg3], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"$h(x_1) = h_1(x_1) + h_2(x_1) + h_3(x_1)$\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$y$\", fontsize=16, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GBM in `sklearn`\n",
    "***\n",
    "Here is a sklearn implementation of GBM with n_estimators = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GBM in `sklearn`\n",
    "***\n",
    "Here is a sklearn implementation of GBM with n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "gbrt_slow = GradientBoostingRegressor(max_depth=2, n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "gbrt_slow.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GBM in `sklearn`\n",
    "***\n",
    "Now let's see how both models vary in terms of decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_predictions([gbrt], X, y, axes=[-0.5, 0.5, -0.1, 0.8], label=\"Ensemble predictions\")\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt.learning_rate, gbrt.n_estimators), fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_predictions([gbrt_slow], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
    "plt.title(\"learning_rate={}, n_estimators={}\".format(gbrt_slow.learning_rate, gbrt_slow.n_estimators), fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GBM in `sklearn`\n",
    "***\n",
    "As we can see, the model with n_estimators = 200 has much higher variance than the one with 3 estimators. This brings us to the **most crucial part of using GBM: Hyperparameter Tuning.**\n",
    "\n",
    "Let's try and understand a bit more about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Improving Gradient Boost\n",
    "***\n",
    "Gradient boosting is a greedy algorithm and can overfit a training dataset quickly.\n",
    "Regularization methods penalize various parts of the algorithm and generally improve the performance of the algorithm by reducing overfitting.\n",
    "\n",
    "The overall parameters can be divided into 3 categories:\n",
    "* **Algorithm-Specific Parameters:** These affect each individual tree in the model\n",
    "* **Training Parameters:** These affect the boosting operation in the model\n",
    "* **Miscellaneous Parameters:** Other parameters for overall functioning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithm specific parameters\n",
    "***\n",
    "#### min_samples_split :\n",
    "\n",
    "* minimum number of samples required at a node to be considered for further splitting.\n",
    "* Controls over-fitting.\n",
    "* Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "* Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "\n",
    "#### min_samples_leaf :\n",
    "* minimum samples required in a terminal node or leaf.\n",
    "* Controls over-fitting.\n",
    "* Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithm specific parameters\n",
    "***\n",
    "#### max_depth :\n",
    "* The maximum depth of a tree.\n",
    "* Controls over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "* Should be tuned using CV.\n",
    "\n",
    "#### max_features :\n",
    "* The number of features to consider while searching for a best split.\n",
    "* These will be randomly selected.\n",
    "* As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "* Higher values may lead to over-fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training parameters\n",
    "***\n",
    "#### learning_rate :\n",
    "* Determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree.\n",
    "* The learning parameter controls the magnitude of this change in the estimates.\n",
    "* Lower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\n",
    "* Lower values would require higher number of trees to model all the relations and will be computationally expensive.\n",
    "\n",
    "#### n_estimators :\n",
    "* The number of sequential trees to be modeled\n",
    "* More robust at higher number of trees but it can still overfit at a point.\n",
    "* Hence, this should be tuned using CV for a particular learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training parameters\n",
    "***\n",
    "#### subsample\n",
    "* The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "* Values slightly less than 1 make the model robust by reducing the variance.\n",
    "* Typical values ~0.8 generally work fine but can be fine-tuned further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Misc Parameters\n",
    "***\n",
    "#### loss\n",
    "* It refers to the loss function to be minimized in each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lucius is not done yet\n",
    "***\n",
    "Lucius had that proud smile when he finished explaining all those things. But something told John that he was not quite done yet. And right John was!\n",
    "\n",
    "There has been a recent implementation of GBM which has suddenly made it one the most popular ML algorithm out there, said Lucius, still glancing at an official documentation page of a website. The name read - **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "# XGBoost\n",
    "***\n",
    "* XGBoost stands for **eXtreme Gradient Boosting**.\n",
    "* XGBoost has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data.\n",
    "* XGBoost is an implementation of gradient boosted decision trees designed for speed and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## XGBoost\n",
    "***\n",
    "* Gradient boosting machines are generally very slow in implementation because of sequential model training. Hence, they are not very scalable\n",
    "* However, it all changed with XGboost Library\n",
    "* The library is laser focused on computational speed and model performance, as such there are few frills.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## XGboost System Features - Lucius can't believe his eyes\n",
    "***\n",
    "* The library provides a system for use in a range of computing environments, not least:\n",
    "* Parallelization of tree construction using all of your CPU cores during training.\n",
    "* Distributed Computing for training very large models using a cluster of machines.\n",
    "* Out-of-Core Computing for very large datasets that don’t fit into memory.\n",
    "* Cache Optimization of data structures and algorithm to make best use of hardware.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XGBoost Execution Speed - Lucius can't believe his eyes\n",
    "***\n",
    "According [this](http://datascience.la/benchmarking-random-forest-implementations/) speed benchmarking study showed that XGBoost was almost always faster than the other benchmarked implementations from R, Python Spark and H2O.\n",
    "\n",
    "![](../images/image34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## `XGBoost` Implementation - `sklearn` style\n",
    "***\n",
    "XGBoost has the same api as sklearn that we have learnt so far. Let's see how it works on John's problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('../data/loan_prediction.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset.iloc[:,0:-1]\n",
    "Y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size,\n",
    "    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Saving and Loading trained model\n",
    "***\n",
    "We can also save and retrieve xgboost (or any other) model in/from a pickle file with a single line of command. It is in general a good practice to save your trained models so that you don't have to start from scratch every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save model to file\n",
    "pickle.dump(model, open(\"loan.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load model from file\n",
    "loaded_model = pickle.load(open(\"loan.pickle.dat\", \"rb\"))\n",
    "# y_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Importances\n",
    "***\n",
    "Just like any other tree based method, xgboost also gets you the feature importances. More importantly you can print and observe the feature importances from an internal api of xgboost. Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot feature importance using built-in function\n",
    "from xgboost import plot_importance\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Early Stopping:\n",
    "***\n",
    "It was late in the night and Lucius, with red eyes, was looking at a website called [machine learning mastery](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/). The website was talking about an interesting concept called 'early stopping'. The website read:\n",
    "\n",
    "> Early stopping is an approach to training complex machine learning models to avoid overfitting.\n",
    "\n",
    "> It works by monitoring the performance of the model that is being trained on a separate test dataset and stopping the training procedure once the performance on the test dataset has not improved after a fixed number of training iterations.\n",
    "\n",
    "> It avoids overfitting by attempting to automatically select the inflection point where performance on the test dataset starts to decrease while performance on the training dataset continues to improve as the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XGBoost Model Configuration\n",
    "***\n",
    "\n",
    "Same as GBM in sklearn, XGBoost has parameters in 3 categories:\n",
    "\n",
    "* **General Parameters:** Guide the overall functioning\n",
    "* **Booster Parameters:** Guide the individual booster (tree/regression) at each step\n",
    "* **Learning Task Parameters:** Guide the optimization performed\n",
    "\n",
    "They are similar to GBM parameter configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XGBoost Model Configuration\n",
    "***\n",
    "And finally to get John started with building a model, Lucius referred him to another article. According to [that article](https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur), following are suggested values for hyperparameters\n",
    "\n",
    "\n",
    "![](../images/image33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## With great power comes great responsibilities\n",
    "***\n",
    "Seemed like Lucius was finally done and returning to his normal human state. He uttered a few words of cautions before finally closing the lid of John's laptop:\n",
    "\n",
    "* XGBoost can be **sensitive to noisy** data and might **overfit**\n",
    "* XGBoost **needs much more hyperparameter** tuning than bagged decision trees\n",
    "\n",
    "With this, the evening which was supposed to be spent with alcohol, was spent with a different kind of spirit, a more mathematical in nature, and both John and Lucius seemed riding those high spirits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score , roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv(\"../data/adult1.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Explore the data by completing the following tasks?\n",
    "- How many men and women (sex feature) are represented in this dataset? \n",
    "\n",
    "- What is the average age (age feature) of women? \n",
    "\n",
    "- What is the percentage of German citizens (native-country feature)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For people who recieve more than 50K per year (salary feature), what is the mean and standard deviation of their age?  Simiarly for people who receive less than 50K per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Display the statistics of age for each gender of all the races (race feature). Use groupby() and describe(). Find the maximum age of men of Amer-Indian-Eskimo race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. As computers understand only numbers, we will do some preprocessing tasks for encoding the categorical features.\n",
    "\n",
    "- Encode Salary column such that wherever we have salary more than 50k that is '>50k' we encode it to 1 else 0. \n",
    "- One hot encode the categorical features.\n",
    "- Split features and target variable into X and y respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following operation on dataset.\n",
    "- Split the data X and y into X_train,X_test,y_train and y_test in the ratio 70:30\n",
    "- Further split the training data into train and validation in 80:20 ratio\n",
    "- Then apply the base Decision Tree Classifier model and calculate the accuracy on validation data as well as on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform ensembling using the models Decision Tree Classifier and Logistic Regression, using a VotingClassifier keeping the parameter voting as `soft` and the calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = LogisticRegression()\n",
    "\n",
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Effect of adding more trees\n",
    "\n",
    "- Train 3 different ensemble classifiers in the form of gradient boosted trees. Train models with 10, 50 and  100 trees.Use the n_estimators parameter in the boosted tree module.\n",
    "\n",
    "- n-estimators:\n",
    "    - The number of sequential trees to be modeled \n",
    "    - Though GBM is fairly robust at higher number of trees but it can still overfit at a point.\n",
    "\n",
    "- Let's get sarted with a model with n_estimators = 10 and max_depth=6:\n",
    "\n",
    "\n",
    "```python\n",
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6).fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Perform the following Boosting task on below two models.\n",
    "\n",
    "- Train two models with \n",
    "```python\n",
    "A) n_estimators = 50 & max_depth = 6\n",
    "B) n_estimators =100 & max_depth= 6\n",
    "```\n",
    "- Calculate the accuracy on validation data and testing data.\n",
    "\n",
    "**Things to ponder**\n",
    "\n",
    "- Which model has the best accuracy on the validation data?\n",
    "- Is it always true that the model with the most trees will perform best on validation data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on the best gradient boosting classifier you found in the previous task, plot a bar plot of the model's top 10 features with it's feature importance score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot the training and testing error vs. number of trees\n",
    "\n",
    "- Steps to follow:\n",
    "\n",
    "**Step 1: Calculate the classification error for model on the training data (train_data).**\n",
    "```python\n",
    "train_err_10 = 1-model_10.score(X_train,y_train)\n",
    "```\n",
    "\n",
    "**Step 2: Store the training errors into a list (called training_errors) that looks like this:**\n",
    "\n",
    "```python \n",
    "[train_err_10, train_err_50, train_err_100]\n",
    "```\n",
    "**Step 3: Calculate the classification error of each model on the validation data (validation_data).**\n",
    "\n",
    "**Step 4: Store the validation classification error into a list (called validation_errors) that looks like this:**\n",
    "\n",
    "```python\n",
    "[validation_err_10, validation_err_50,validation_err_100]\n",
    "```\n",
    "**Step 5: Calculate the classification error of each model on the test data (test_data).**\n",
    "\n",
    "**Step 6: Store the testing classification error into a list (called testing_errors) that looks like this:**\n",
    "```python\n",
    "[testing_err_10, testing_err_50,testing_err_100]\n",
    "```\n",
    "\n",
    "**Things to ponder**\n",
    "\n",
    "- Does the training error reduce as the number of trees increases?Is it always true that the validation error will reduce as the number of trees increases?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Recap.png\" alt=\"Recap\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "# In-session Recap Time\n",
    "***\n",
    "* What is Boosting?\n",
    "* Intuitive understanding of Boosting\n",
    "* AdaBoost\n",
    "* Intuitive understanding of Gradient Boosting\n",
    "* Boosting in sklearn\n",
    "* XGBoost\n",
    "* Hyper parameter tuning of XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Challenges in ML & Clustering Algorithm"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
