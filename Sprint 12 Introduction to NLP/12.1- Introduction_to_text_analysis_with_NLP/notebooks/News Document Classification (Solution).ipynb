{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>20 Newsgroups data</center>\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian). Here is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "```python\n",
    "comp.graphics\n",
    "comp.os.ms-windows.misc\n",
    "comp.sys.ibm.pc.hardware\n",
    "comp.sys.mac.hardware\n",
    "comp.windows.x\t\n",
    "rec.autos\n",
    "rec.motorcycles\n",
    "rec.sport.baseball\n",
    "rec.sport.hockey\n",
    "sci.crypt\n",
    "sci.electronics\n",
    "sci.med\n",
    "sci.space\n",
    "misc.forsale\t\n",
    "talk.politics.misc\n",
    "talk.politics.guns\n",
    "talk.politics.mideast\n",
    "talk.religion.misc\n",
    "alt.atheism\n",
    "soc.religion.christian\n",
    "```\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset which will be automatically downloaded and then cached and reused for the document classification example.\n",
    "\n",
    "You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score , f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "df = fetch_20newsgroups(subset='train')\n",
    "pprint(list(df.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create a list of 4 newsgroup and fetch it using function `fetch_20newsgroups` for both train and test data.\n",
    "***\n",
    "### Instructions\n",
    "\n",
    "- Create a list of 4 newsgroup i.e `'alt.atheism'`, `'talk.religion.misc'`, `'comp.graphics'`, `'sci.space'` and save it as `categories`\n",
    "- Fetch 4 newsgroup using function `fetch_20newsgroups` with parameters as `subset='train'`,`categories=categories` and store it in `newsgroups_train` variable. Similarly do it for test and store in `newsgroups_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Use TfidfVectorizer on train data and find out the Number of Non-Zero components per sample.\n",
    "***\n",
    "### Instructions\n",
    " - Initialise a `TfidfVectorizer()` object and save it as `vectorizer`\n",
    " - Apply the \"fit_transform()\" method of `vectorizer` on `newsgroups_train.data` and store the result in `vectors`\n",
    " - Print the distribution count of the `vectors`\n",
    " - Find out the Number of Non-Zero components per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 34118)\n",
      "159.0132743362832\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "print(vectors.shape)\n",
    "print(vectors.nnz / float(vectors.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:- The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero components by sample in a more than 30000-dimensional space (i.e. less than .5% non-zero features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Use TfidfVectorizer on test data and apply Naive Bayes model and calculate f1_score.\n",
    "***\n",
    "### Instructions\n",
    "- Apply the `transform()` method  on `newsgroups_test.data` and store the result in `vectors_test`\n",
    "- Initialise a naive bayes model with `MultinomialNB()` having parameter as `alpha=.01` and save it to a variable called `clf`\n",
    "- Apply the `fit()` method of `clf` on `vectors` and `newsgroups_train.target`\n",
    "- Predict on test data i.e `vectors_test` and save it as `pred`\n",
    "- Find out the f1 score between `newsgroups_test.target` and `pred` using the `f1_score` method also pass parameter as `average = 'macro'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.8821359240272957\n"
     ]
    }
   ],
   "source": [
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "pred = clf.predict(vectors_test)\n",
    "print(\"f1_score: \",f1_score(newsgroups_test.target, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Print the top 20 news category and top 20 words for every news category.\n",
    "***\n",
    "As we see that Multinomial Naive Bayes gets a higher F-score of 0.88. You might be thinking what’s going on inside this classifier?\n",
    "\n",
    "Let’s take a look at what the most informative features are:\n",
    "- Create a function `show_top20` with 3 parameters as `classifier`, `vectorizer`, `categories`\n",
    "- Get the feature names using `get_feature_names()` attribute of `vectorizer` and convert it into array and save it as `feature_names`.\n",
    "- Start a `for` loop to iterate over both the index and value of `categories` using `enumerate()` function\n",
    "- Inside the for loop, sort the top 20 coefficient using `argsort()` function of numpy by passing parameter as `classifier.coef_[i][-20]` and save it as in variable `top20`\n",
    "- Print out the corresponding value (`categories` i.e. news category) and top 20 words for every news category\n",
    "- And then call the function as `show_top20(clf, vectorizer, newsgroups_train.target_names)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: for com as have this be god are keith not edu it and in you that is of to the\n",
      "comp.graphics: university any can or have this on you that from edu in graphics it is for and of to the\n",
      "sci.space: access from this henry was be you on for nasa edu it that is in and space to of the\n",
      "talk.religion.misc: for be this as he sandvik are edu god com not it you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def show_top20(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top20 = np.argsort(classifier.coef_[i])[-20:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top20])))\n",
    "show_top20(clf, vectorizer, newsgroups_train.target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
